{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b582398b",
   "metadata": {},
   "source": [
    "# Test Predictions\n",
    "The following notebook imports the final model and applies it to the test set. The predictions are then copied over to the project page and graded. The final accuracy will be revealed. \n",
    "\n",
    "First          attempt: 67.2% test accuracy - 9 window no extra stats\n",
    "\n",
    "Second         attempt: 34.4% test accuracy - 19 window w extra stats only trained on labelled data\n",
    "- did wrong, window must be on raw time series then take the readings out\n",
    "\n",
    "Third (proper) attempt: 58.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06963603",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90698bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a48f068",
   "metadata": {},
   "source": [
    "Import data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ad3d93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "train_X, test_X, train_Y = import_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c14dfdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3733, 27)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e093178",
   "metadata": {},
   "source": [
    "Import model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dd917e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "rf_model = pickle.load(open('rf_model.pkl','rb')) \n",
    "boost_model = pickle.load(open('boost_model.pkl','rb'))\n",
    "rf_model_upgraded = pickle.load(open('rf_model_19_window_extra_stats.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188a3d6",
   "metadata": {},
   "source": [
    "Test model on training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c388b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9518716577540107\n"
     ]
    }
   ],
   "source": [
    "training_prediction = rf_model.predict(train_X)\n",
    "# grab only required labels\n",
    "training_prediction = np.hstack((training_prediction[(10*np.linspace(0,372,373)).astype(int)+5], \n",
    "                                      training_prediction[-1]))\n",
    "print((training_prediction==train_Y).mean())\n",
    "\n",
    "# the accuracy is slightly lower than the training accuracy from the training workbook, \n",
    "#     because the validation data is now included"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e00a598",
   "metadata": {},
   "source": [
    "Make prediction on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cfa155d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = rf_model.predict(test_X)\n",
    "test_predictions = np.hstack((test_predictions[(10*np.linspace(0,123,124)).astype(int)], \n",
    "                                      test_predictions[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8746f3",
   "metadata": {},
   "source": [
    "Print in required format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f43a1bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3, 4, 4, 2, 3, 2, 2, 3, 2, 2, 4, 2, 3, 2, 4, 4, 2, 2, 4, 3, 4, 3, 3, 3, 2, 4, 3, 3, 4, 4, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 3, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, "
     ]
    }
   ],
   "source": [
    "for i in range(len(test_predictions)):\n",
    "    print('%d, ' % (test_predictions[i]),end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e196441b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89788a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeddfe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "e67ab363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified to edit test data as well into required format\n",
    "\n",
    "def import_data():\n",
    "    # import data into groups of 3 and give labels according to the groups of 10\n",
    "    train_labels = pd.read_csv('https://courses.edx.org/assets/courseware/v1/d64e74647423e525bbeb13f2884e9cfa/asset-v1:HarvardX+PH526x+2T2020+type@asset+block/train_labels.csv',index_col=0)\n",
    "    train_time_series = pd.read_csv('https://courses.edx.org/assets/courseware/v1/b98039c3648763aae4f153a6ed32f38b/asset-v1:HarvardX+PH526x+2T2020+type@asset+block/train_time_series.csv',index_col=0)\n",
    "    test_labels = pd.read_csv('https://courses.edx.org/assets/courseware/v1/72d5933c310cf5eac3fa3f28b26d9c39/asset-v1:HarvardX+PH526x+2T2020+type@asset+block/test_labels.csv',index_col=0)\n",
    "    test_time_series = pd.read_csv('https://courses.edx.org/assets/courseware/v1/1ca4f3d4976f07b8c4ecf99cf8f7bdbc/asset-v1:HarvardX+PH526x+2T2020+type@asset+block/test_time_series.csv',index_col=0)\n",
    "\n",
    "    # remove first four entires in training set\n",
    "    train_labels = train_labels.iloc[1:, :]\n",
    "    train_time_series = train_time_series.iloc[4:,:]\n",
    "\n",
    "    # pop off unecassary features\n",
    "    train_time_series.pop('accuracy')\n",
    "    test_time_series.pop('accuracy')\n",
    "\n",
    "    train_time_series.pop('UTC time')\n",
    "    test_time_series.pop('UTC time')\n",
    "\n",
    "    train_time_series.pop('timestamp')\n",
    "    test_time_series.pop('timestamp')\n",
    "\n",
    "    # normalise accelerometer readings\n",
    "    train_time_series[['x','y','z']] = (train_time_series[['x','y','z']] - train_time_series[['x','y','z']].mean())/(train_time_series[['x','y','z']].max() - train_time_series[['x','y','z']].min())\n",
    "    test_time_series[['x','y','z']] = (test_time_series[['x','y','z']] - test_time_series[['x','y','z']].mean())/(test_time_series[['x','y','z']].max() - test_time_series[['x','y','z']].min())\n",
    "\n",
    "    # organise into numpy array for training\n",
    "    train_X = train_time_series.to_numpy()\n",
    "    test_X = test_time_series.to_numpy()\n",
    "    train_Y = train_labels['label'].to_numpy()\n",
    "\n",
    "        \n",
    "    # copy x y z from two time steps before and after\n",
    "    train_X_top = np.concatenate((train_X[4:-4,:],\n",
    "                              train_X[0:-8,:],\n",
    "                              train_X[1:-7,:],\n",
    "                              train_X[2:-6,:],\n",
    "                              train_X[3:-5,:],\n",
    "                              train_X[5:-3,:],\n",
    "                              train_X[6:-2,:],\n",
    "                              train_X[7:-1,:],\n",
    "                              train_X[8:,:])\n",
    "                             ,axis=1) # horizontally\n",
    "    \n",
    "    \n",
    "    # construct row for the final observation, repeat bottom half of time window because incomplete for final reading\n",
    "    train_X_bottom = np.concatenate((train_X[-1,:], \n",
    "                                 train_X[-5, :],\n",
    "                                 train_X[-4, :],\n",
    "                                 train_X[-3, :],\n",
    "                                 train_X[-2, :],\n",
    "                                 train_X[-2, :],\n",
    "                                 train_X[-3, :],\n",
    "                                 train_X[-4, :],\n",
    "                                 train_X[-5, :]),\n",
    "                                axis=0) # horizontally, but they're 0 dim vectors so axis must equal 0\n",
    "    \n",
    "    train_X = np.vstack((train_X_top, train_X_bottom)) # veritcally\n",
    "    \n",
    "    \n",
    "    test_X_top = np.concatenate((test_X[4:-4,:],\n",
    "                              test_X[0:-8,:],\n",
    "                              test_X[1:-7,:],\n",
    "                              test_X[2:-6,:],\n",
    "                              test_X[3:-5,:],\n",
    "                              test_X[5:-3,:],\n",
    "                              test_X[6:-2,:],\n",
    "                              test_X[7:-1,:],\n",
    "                              test_X[8:,:]),\n",
    "                              axis=1) # horizontally\n",
    "    \n",
    "    \n",
    "    # construct row for the final observation, repeat bottom half of time window because incomplete for final reading\n",
    "    test_X_bottom = np.concatenate((test_X[-1,:], \n",
    "                                 test_X[-5, :],\n",
    "                                 test_X[-4, :],\n",
    "                                 test_X[-3, :],\n",
    "                                 test_X[-2, :],\n",
    "                                 test_X[-2, :],\n",
    "                                 test_X[-3, :],\n",
    "                                 test_X[-4, :],\n",
    "                                 test_X[-5, :]),\n",
    "                                   axis=0) # horizontally, but they're 0 dim vectors so axis must equal 0\n",
    "    \n",
    "    test_X = np.vstack((test_X_top, test_X_bottom)) # veritcally\n",
    "\n",
    "        \n",
    "    # checks\n",
    "    if(test_X.shape[1] != train_X.shape[1]):\n",
    "        print('Error 1')\n",
    "        print('\\t No. col  test: %d' % (test_X.shape[1]))\n",
    "        print('\\t No. col train: %d' % (train_X.shape[1]))\n",
    "\n",
    "    \n",
    "    return train_X, test_X, train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ea1ce732",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('https://courses.edx.org/assets/courseware/v1/d64e74647423e525bbeb13f2884e9cfa/asset-v1:HarvardX+PH526x+2T2020+type@asset+block/train_labels.csv',index_col=0)\n",
    "train_time_series = pd.read_csv('https://courses.edx.org/assets/courseware/v1/b98039c3648763aae4f153a6ed32f38b/asset-v1:HarvardX+PH526x+2T2020+type@asset+block/train_time_series.csv',index_col=0)\n",
    "train_time_series[['x','y','z']] = (train_time_series[['x','y','z']] - train_time_series[['x','y','z']].mean())/(train_time_series[['x','y','z']].max() - train_time_series[['x','y','z']].min())\n",
    "train_labels = train_labels.iloc[1:, :]\n",
    "train_time_series = train_time_series.iloc[4:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e80539ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data_19_window_w_extra_stats():\n",
    "    # import data into groups of 3 and give labels according to the groups of 10\n",
    "    train_labels = pd.read_csv('https://courses.edx.org/assets/courseware/v1/d64e74647423e525bbeb13f2884e9cfa/asset-v1:HarvardX+PH526x+2T2020+type@asset+block/train_labels.csv',index_col=0)\n",
    "    train_time_series = pd.read_csv('https://courses.edx.org/assets/courseware/v1/b98039c3648763aae4f153a6ed32f38b/asset-v1:HarvardX+PH526x+2T2020+type@asset+block/train_time_series.csv',index_col=0)\n",
    "    test_labels = pd.read_csv('https://courses.edx.org/assets/courseware/v1/72d5933c310cf5eac3fa3f28b26d9c39/asset-v1:HarvardX+PH526x+2T2020+type@asset+block/test_labels.csv',index_col=0)\n",
    "    test_time_series = pd.read_csv('https://courses.edx.org/assets/courseware/v1/1ca4f3d4976f07b8c4ecf99cf8f7bdbc/asset-v1:HarvardX+PH526x+2T2020+type@asset+block/test_time_series.csv',index_col=0)\n",
    "\n",
    "    # remove first four entires in training set\n",
    "    train_labels = train_labels.iloc[1:, :]\n",
    "    train_time_series = train_time_series.iloc[4:,:]\n",
    "\n",
    "    # pop off unecassary features\n",
    "    train_time_series.pop('accuracy')\n",
    "    test_time_series.pop('accuracy')\n",
    "\n",
    "    train_time_series.pop('UTC time')\n",
    "    test_time_series.pop('UTC time')\n",
    "\n",
    "    train_time_series.pop('timestamp')\n",
    "    test_time_series.pop('timestamp')\n",
    "\n",
    "    # normalise accelerometer readings\n",
    "    train_time_series[['x','y','z']] = (train_time_series[['x','y','z']] - train_time_series[['x','y','z']].mean())/(train_time_series[['x','y','z']].max() - train_time_series[['x','y','z']].min())\n",
    "    test_time_series[['x','y','z']] = (test_time_series[['x','y','z']] - test_time_series[['x','y','z']].mean())/(test_time_series[['x','y','z']].max() - test_time_series[['x','y','z']].min())\n",
    "\n",
    "    # organise into numpy array for training\n",
    "    train_X = train_time_series.to_numpy()\n",
    "    test_X = test_time_series.to_numpy()\n",
    "    train_Y = train_labels['label'].to_numpy()\n",
    "            \n",
    "    # copy x y z from two time steps before and after\n",
    "    train_X_top = np.concatenate((train_X[9:-9,:],\n",
    "                              train_X[0:-18,:],\n",
    "                              train_X[1:-17,:],\n",
    "                              train_X[2:-16,:],\n",
    "                              train_X[3:-15,:],\n",
    "                              train_X[4:-14,:],\n",
    "                              train_X[5:-13,:],\n",
    "                              train_X[6:-12,:],\n",
    "                              train_X[7:-11,:],\n",
    "                              train_X[8:-10,:],\n",
    "                              train_X[10:-8,:],\n",
    "                              train_X[11:-7,:],\n",
    "                              train_X[12:-6,:],\n",
    "                              train_X[13:-5,:],\n",
    "                              train_X[14:-4,:],\n",
    "                              train_X[15:-3,:],\n",
    "                              train_X[16:-2,:],\n",
    "                              train_X[17:-1,:],\n",
    "                              train_X[18:,:])\n",
    "                             ,axis=1) # horizontally\n",
    "    \n",
    "     # construct row for the final observation, repeat bottom half of time window because incomplete for final reading\n",
    "    train_X_bottom = np.concatenate((train_X[-1,:], \n",
    "                                 train_X[-10, :],\n",
    "                                 train_X[-9, :],\n",
    "                                 train_X[-8, :],\n",
    "                                 train_X[-7, :],\n",
    "                                 train_X[-6, :],\n",
    "                                 train_X[-5, :],\n",
    "                                 train_X[-4, :],\n",
    "                                 train_X[-3, :],\n",
    "                                 train_X[-2, :],\n",
    "                                 train_X[-10, :],\n",
    "                                 train_X[-9, :],\n",
    "                                 train_X[-8, :],\n",
    "                                 train_X[-7, :],\n",
    "                                 train_X[-6, :],\n",
    "                                 train_X[-5, :],\n",
    "                                 train_X[-4, :],\n",
    "                                 train_X[-3, :],\n",
    "                                 train_X[-2, :]),\n",
    "                                axis=0) # horizontally, but they're 0 dim vectors so axis must equal 0\n",
    "    \n",
    "    train_X = np.vstack((train_X_top, train_X_bottom)) # veritcally\n",
    "    \n",
    "    \n",
    "    # add mean x and z, as well as x std - across the 19 observations in the window - as features\n",
    "    x_values = train_X[:,3*np.linspace(0,18,19).astype(int)]\n",
    "    y_values = train_X[:,3*np.linspace(0,18,19).astype(int)+1]\n",
    "    z_values = train_X[:,3*np.linspace(0,18,19).astype(int)+2]\n",
    "    x_mean = np.mean(x_values, axis=1)\n",
    "    y_mean = np.mean(y_values, axis=1)\n",
    "    z_mean = np.mean(z_values, axis=1)\n",
    "    x_std = np.std(x_values, axis=1)\n",
    "    y_std = np.std(y_values, axis=1)\n",
    "    z_std = np.std(z_values, axis=1)\n",
    "    \n",
    "    extra_stats = np.vstack(( x_mean, y_mean, z_mean, x_std, y_std,z_std))\n",
    "    train_X = np.concatenate((train_X, extra_stats.T), axis=1)\n",
    "    \n",
    "    # copy x y z from two time steps before and after\n",
    "    test_X_top = np.concatenate((test_X[9:-9,:],\n",
    "                              test_X[0:-18,:],\n",
    "                              test_X[1:-17,:],\n",
    "                              test_X[2:-16,:],\n",
    "                              test_X[3:-15,:],\n",
    "                              test_X[4:-14,:],\n",
    "                              test_X[5:-13,:],\n",
    "                              test_X[6:-12,:],\n",
    "                              test_X[7:-11,:],\n",
    "                              test_X[8:-10,:],\n",
    "                              test_X[10:-8,:],\n",
    "                              test_X[11:-7,:],\n",
    "                              test_X[12:-6,:],\n",
    "                              test_X[13:-5,:],\n",
    "                              test_X[14:-4,:],\n",
    "                              test_X[15:-3,:],\n",
    "                              test_X[16:-2,:],\n",
    "                              test_X[17:-1,:],\n",
    "                              test_X[18:,:])\n",
    "                             ,axis=1) # horizontally\n",
    "    \n",
    "     # construct row for the final observation, repeat bottom half of time window because incomplete for final reading\n",
    "    test_X_bottom = np.concatenate((test_X[-1,:], \n",
    "                                 test_X[-10, :],\n",
    "                                 test_X[-9, :],\n",
    "                                 test_X[-8, :],\n",
    "                                 test_X[-7, :],\n",
    "                                 test_X[-6, :],\n",
    "                                 test_X[-5, :],\n",
    "                                 test_X[-4, :],\n",
    "                                 test_X[-3, :],\n",
    "                                 test_X[-2, :],\n",
    "                                 test_X[-10, :],\n",
    "                                 test_X[-9, :],\n",
    "                                 test_X[-8, :],\n",
    "                                 test_X[-7, :],\n",
    "                                 test_X[-6, :],\n",
    "                                 test_X[-5, :],\n",
    "                                 test_X[-4, :],\n",
    "                                 test_X[-3, :],\n",
    "                                 test_X[-2, :]),\n",
    "                                axis=0) # horizontally, but they're 0 dim vectors so axis must equal 0\n",
    "    \n",
    "    test_X = np.vstack((test_X_top, test_X_bottom)) # veritcally\n",
    "    \n",
    "    \n",
    "    # add mean x and z, as well as x std - across the 19 observations in the window - as features\n",
    "    x_values = test_X[:,3*np.linspace(0,18,19).astype(int)]\n",
    "    y_values = test_X[:,3*np.linspace(0,18,19).astype(int)+1]\n",
    "    z_values = test_X[:,3*np.linspace(0,18,19).astype(int)+2]\n",
    "    x_mean = np.mean(x_values, axis=1)\n",
    "    y_mean = np.mean(y_values, axis=1)\n",
    "    z_mean = np.mean(z_values, axis=1)\n",
    "    x_std = np.std(x_values, axis=1)\n",
    "    y_std = np.std(y_values, axis=1)\n",
    "    z_std = np.std(z_values, axis=1)\n",
    "    \n",
    "    extra_stats = np.vstack(( x_mean, y_mean, z_mean, x_std, y_std,z_std))\n",
    "    test_X = np.concatenate((test_X, extra_stats.T), axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "     # checks\n",
    "    if(test_X.shape[1] != train_X.shape[1]):\n",
    "        print('Error 1')\n",
    "        print('\\t No. col  test: %d' % (test_X.shape[1]))\n",
    "        print('\\t No. col train: %d' % (train_X.shape[1]))\n",
    "\n",
    "    \n",
    "    return train_X, test_X, train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b67ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b582398b",
   "metadata": {},
   "source": [
    "# Test Predictions\n",
    "The following notebook imports the final model and applies it to the test set. The predictions are then copied over to the project page and graded. The final accuracy will be revealed. \n",
    "\n",
    "First          attempt: 67.2% test accuracy - 9 window no extra stats\n",
    "\n",
    "Second         attempt: 34.4% test accuracy - 19 window w extra stats only trained on labelled data\n",
    "- did wrong, window must be on raw time series then take the readings out\n",
    "\n",
    "Third (proper) attempt: 58.4%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06963603",
   "metadata": {},
   "source": [
    "Import libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "90698bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import datetime\n",
    "import pickle\n",
    "\n",
    "# import data extraction functions\n",
    "from data_importing_functions import import_data_19_window_w_extra_stats_for_testing,import_and_split_data_3_window_for_testing  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a48f068",
   "metadata": {},
   "source": [
    "Import data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ad3d93e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "import_data = import_and_split_data_3_window_for_testing\n",
    "train_X, test_X, train_Y = import_data()\n",
    "\n",
    "X_test.shape # validate the data was imported properly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e093178",
   "metadata": {},
   "source": [
    "Import model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "dd917e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "rf_model = pickle.load(open('rf_model.pkl','rb')) \n",
    "boost_model = pickle.load(open('boost_model.pkl','rb'))\n",
    "rf_model_upgraded = pickle.load(open('rf_model_19_window_extra_stats.pkl','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c188a3d6",
   "metadata": {},
   "source": [
    "Test model on training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "c388b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9518716577540107\n"
     ]
    }
   ],
   "source": [
    "training_prediction = rf_model.predict(train_X)\n",
    "# grab only required labels\n",
    "training_prediction = np.hstack((training_prediction[(10*np.linspace(0,372,373)).astype(int)+5], \n",
    "                                      training_prediction[-1]))\n",
    "print((training_prediction==train_Y).mean())\n",
    "\n",
    "# the accuracy is slightly lower than the training accuracy from the training workbook, \n",
    "#     because the validation data is now included"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e00a598",
   "metadata": {},
   "source": [
    "Make prediction on test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "cfa155d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = rf_model.predict(test_X)\n",
    "test_predictions = np.hstack((test_predictions[(10*np.linspace(0,123,124)).astype(int)], \n",
    "                                      test_predictions[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8746f3",
   "metadata": {},
   "source": [
    "Print in required format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f43a1bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3, 4, 4, 2, 3, 2, 2, 3, 2, 2, 4, 2, 3, 2, 4, 4, 2, 2, 4, 3, 4, 3, 3, 3, 2, 4, 3, 3, 4, 4, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 3, 2, 3, 3, 3, 3, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 2, 3, 3, 3, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 3, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, "
     ]
    }
   ],
   "source": [
    "for i in range(len(test_predictions)):\n",
    "    print('%d, ' % (test_predictions[i]),end='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
